---
title: "API Lab"
author: Samin Charepoo
date: Feb 8, 2020
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
---

# Packages for Today
```{r packages}
library(xml2)
library(jsonlite)
library(DT)
library(httr) # for https
```

```{r}
install.packages('plyr', repos = "http://cran.us.r-project.org")
```

Lets look at http://api.plos.org/solr/examples/


Also, look up the function  URLencode, what does it do?

**The functions is to percent-encode or decode characters in URLs**

1. Write a function that takes in a search term for a title, then fetches the results from api.plos.org/, converts them to an R-friendly format, and returns them.




```{r}
searchTerm=function(titel){
  base="http://api.plos.org/search?q=title:"
  htmlresp=GET(paste0(base,titel))
  newjson=fromJSON(content(htmlresp,"text"))
  return(newjson)
  
}
```



2. How many results does the search return at most?

**the search returns at most 10 results**

3. Run your function using some search term and save the output



```{r}
output=searchTerm("DNA")
output

```



4. Extract the abstracts from the results returned and put them in a vector (HINT: you can use str() to learn about the structure of the data you got back so you can figure out how to access the column names) 

```{r}
str(output)
```

```{r}
str(output[[1]])
```




```{r}
extraction<-as.data.frame(output)
extraction

```
```{r}
abstract <- as.vector(extraction['response.docs.abstract'])
for(i in abstract){ 
  print(i)
}
abstract
```



















5. Follow the instructions here to create a word cloud from your abstracts

http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know

Note 1: since you already have a list of abstracts, you can use that as the input on Step 2, and skip Step 1.

Note 2: when you do the text transformations you might get a warning that "transformation drops documents" but that didn't actually happen for me (that is, I still had 10 documents at the end), so you can probably ignore it.

#step2
```{r}
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator 
install.packages("RColorBrewer") # color palettes
# Load
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
```

#step3
```{r}
docs<-Corpus(VectorSource(abstract))
```

```{r}
inspect(docs)
```

#textTransformation

```{r}
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
```
```{r}
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
```
#step4
```{r}
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
```

#step5
```{r}
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=150, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```



When you are done creating the word cloud, answer the following questions:

1. Why is it important to remove stopwords? What happens to your word cloud if you skip that step?

**it is important to remove the stop words because removing stop words will improve the accuracy of the words that are acually most frequently used. If we skip this step, our word cloud would be filled with words that have no information value due to the fact that they are used so much, so words like 'the' or 'also' would be claimed as most frequent, when even though they are, they are not actually not that informative to us for the word cloud.**

2. Change some of the settings on the word cloud function. What do these parameters do? min.freq, max.words, random.order? What are other options for the colors parameter?

**min.freq is changing the range of the frequency the cloud will detect. max.words is the maximum number of words that will be plotted/shown in the word cloud. random.order determines if it will be plotting words in random order, false is decreasing frequency so that the largest is in the center and the further from the center, the less frequent it is, and true is random. Other options for colors parameter is 'BuGn', 'Spectral', "BrBG' and more. you can see the list of options for the color parameters using 'display.brewer.all()'**


